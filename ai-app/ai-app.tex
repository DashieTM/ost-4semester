\documentclass[main.tex,fontsize=8pt,paper=a4,paper=portrait,DIV=calc,]{scrartcl}
\input{../ost-summary-template.tex}

\begin{document}
\tableofcontents

\lstset{
    language=Python,
    style=code,
}

\newcommand{\TITLE}{AI Applications}
\newcommand{\AUTHOR}{Fabio Lenherr}
\setcounter{tocdepth}{1}

\section{CNN Convolutional Neural Networks}

\subsection{Keras}
A python library that wraps tensorflow for classification.\newline
We will use this in this module to classify images like so:\newline
\includegraphics[scale=0.4]{2023_02_20_12_32_47.png}

\subsection{Flattening}
When we convert an image into a long vector, we lose information in the human sense, or rather make it hidden.\newline
todo, explain what is hidden and why


\section{Convolution}
\subsection{Firing of neurons}
Neurons are clearly connected to something very specific, this would then also be reflected in the artificial neural network. In other words, neuron 1 handles horizontal lines, another a line with a slight angle and so-on.\newline
\includegraphics[scale=0.4]{2023_02_20_02_19_00.png}

\subsection{mathematical model of a feature detector}
\begin{itemize}
\item \textcolor{purple}{Two Inputs}\newline
  \begin{itemize}
  \item \textcolor{orange}{a picture}\newline
    Note that rgb would give you 3 channels red, green and blue
  \item \textcolor{orange}{A filter(kernel)}\newline
  \begin{itemize}
  \item  an m by n matrix in the simplest case (1 channel, grayscale).
  \item an m by n x 3 "stack of matrices" in the case of a 3 channel input (e.g. an RGB image)
  \item an m by n x d "stack of matrices". The depth of the kernel must equal the number of input channels.
  \end{itemize} 
\end{itemize} 
\item \textcolor{purple}{One Output}\newline
  A feature map (where is the thing that we wanted to search / determine by)\newline
  One convolution produces one feature map. Even if the input and the filter have multiple channels, the output of the convolution has one channel.
\item \textcolor{purple}{The Operation: Convolution}\newline
  We convolve the input image with the convolutional kernel
\end{itemize} 

\subsection{Example of convolution}
\includegraphics[scale=0.4]{2023_02_20_02_23_12.png}\newline
As you can see here, a filter will be used to detect something specific, like a pattern.\newline
\textcolor{purple}{This means that you will be combining multiple different filters in order to properly figure out what picture the underlying image is composed of.}\newline
\includegraphics[scale=0.4]{2023_02_20_02_23_46.png}\newline
\textcolor{purple}{Explanation for the first calculation: 0 * -1 + 0 * -1 + 0 * 1 + 0 * 0 + 156 * 1 + 155 * -1 + 0 * 0 + 153 * 1 + 154 * 1 = 308}\newline
multiply each number in the top red square with the number in the same position in the bottom square.
We then proceed to do this for all channels (complexity of input, 3 for rgb), which \emph{will then be combined to 1 single output value}.\newline
This output value will then also be combined with a \emph{bias}.\newline
\textcolor{purple}{The entire reason we do this, is so that we can have an easier time calculating the images with a pc.}

\subsection{Reasons for convolution}
\begin{itemize}
\item \textcolor{purple}{Features can be detected independent of location -> filters will always find what they are supposed/created to find}
\item \textcolor{purple}{This calculation is done in parallel, which is very fast for gpus when doing matrix calculations! -> Hence the use of tensorflow with cuda!}
\item \textcolor{purple}{Shared weights mean using the same \emph{kernel values}, this reduces the use of a singular value for each neuron. -> more processing etc}
\end{itemize} 

\subsection{Stride}
\includegraphics[scale=0.4]{2023_02_20_02_44_29.png}\newline
\textcolor{purple}{Stride is simply the offset by which we move towards the right and the bottom when we move to the next calculation.}\newline
The default value here is 1, which means Stride 1.

\subsection{Padding}
\minipg{
Padding is simply the edge of the matrix that has been predefined.\newline
A same padding is made entirely of 0's!\newline
\textcolor{purple}{Note, with padding, we can effectively go over the bounds of the matrix!}
}{
\includegraphics[scale=0.4]{2023_02_20_02_47_01.png}
}[0.45,0.4]

\subsection{Max Pooling}
\includegraphics[scale=0.4]{2023_02_20_02_46_05.png}\newline
\includegraphics[scale=0.4]{2023_02_20_02_48_45.png}\newline
Max pooling simplyfies the image by taking the maximum value in each sector.\newline
For example in the first red square, the highest value will be placed in the right red square.\newline
Similar to before, we then iterate with the stride as the length to iterate and do this again and again until we are done.

\subsection{Example with Keras}
\begin{lstlisting}
model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
\end{lstlisting}
\includegraphics[scale=0.4]{2023_02_27_01_28_25.png}

\subsection{Softmax}
\textcolor{purple}{Softmax is used to get the probabilities of each classification.}
\includegraphics[scale=0.4]{2023_02_27_05_50_28.png}

\subsection{Drop Out}
\textcolor{purple}{This is similar but not quite the same as emsemble method learning.\newline
It is used to get models that are more robust than otherwise.}\newline
\textcolor{teal}{This entire ordeal is done during training, not during inference!}
\includegraphics[scale=0.4]{2023_02_27_05_54_10.png}




\subsection{Why?}
The entire filter is essentially just a shape, packed into a matrix.\newline
If you for example have a filter of a 2x2 matrix and you only fill the bottom left and top right square with one and the others with 0, then you will detect whether or not the shape in question has a diagonal line inside of it.\newline
Note that with the others being 0, you will \emph{ignore} the rest of the shape around it. This means you will detect ALL diagonal lines, \emph{even if they are within another shape.}.\newline
\textcolor{purple}{Should you want to only detect diagonal lines that have no other color around it, then you need to make the other values in the filter matrix as negative, indicating that you only want the diagonal lines that are isolated.}\newline
\includegraphics[scale=0.4]{2023_02_21_09_51_55.png}

\subsection{Tensor}
A tensor is just a multidimensional array. The structure is as follows:\newline
\includegraphics[scale=0.4]{2023_02_21_09_56_23.png}\newline
In other words: \textcolor{purple}{\emph{amount of sub-arrays, width of sub-array, length of sub-array}}\newline
\textcolor{teal}{Tensors are immutable, meaning you can only create new ones, you can't update them!}\newline
Terms:
\begin{itemize}
  \item \textcolor{orange}{Rank} \newline
    The amount of parameters, in the example we had rank3, but what if the sub-arrays had a height as well? -> rank 4!
\item \textcolor{orange}{Axis or Dimension}\newline
  a particular dimension of a tensor, remember 3 dimensions = rank3\newline
  A rank-4 tensor, shape: [3, 2, 4, 5]
\item \textcolor{orange}{Shape}\newline
  The length (number of elements) of each of the axes of a tensor.
\item \textcolor{orange}{Size}\newline
  The total number of items in the tensor, the product of the shape vector's elements.
\item \textcolor{orange}{Indexing}\newline
  simply the indexing of the array like in python.
  \begin{lstlisting}
  rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
  print(rank_1_tensor.numpy())
  print("First:", rank_1_tensor[0].numpy())
  print("Second:", rank_1_tensor[1].numpy())
  print("Last:", rank_1_tensor[-1].numpy())
  # First: 0
  # Second: 1
  # Last: 34
  \end{lstlisting}
\item \textcolor{orange}{Reshaping}\newline
  reshapes a vector by a given list. -> shape is a list!\newline
  Remember that the order and amount of axis need to match! Otherwise you get trash!
  \begin{lstlisting}
  # Shape returns a `TensorShape` object that shows the size along each axis
  x = tf.constant([[1], [2], [3]])
  print(x.shape)
  # You can reshape a tensor to a new shape.
  # Note that you're passing in a list
  reshaped = tf.reshape(x, [1, 3])
  print(x.shape)
  print(reshaped.shape)
  # (3, 1)
  # (1, 3)
  \end{lstlisting}
\item \textcolor{orange}{Broadcasting}\newline
  When tensors aren't the same size, you can essentially default extend them, in this case the last value will be taken.
  \begin{lstlisting}
  x = tf.constant([1, 2, 3])
  y = tf.constant(2)
  z = tf.constant([2, 2, 2])
  # All of these are the same computation
  print(tf.multiply(x, 2))
  print(x * y)
  print(x * z)
  # tf.Tensor([2 4 6], shape=(3,), dtype=int32)
  # tf.Tensor([2 4 6], shape=(3,), dtype=int32)
  # tf.Tensor([2 4 6], shape=(3,), dtype=int32)
  \end{lstlisting}
\end{itemize} 
\href{https://www.tensorflow.org/guide/tensor}{code tutorial}

\subsection{An example for image classification}
\begin{lstlisting}
# import necessary modules
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# show pictures
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    # The CIFAR labels happen to be arrays, 
    # which is why you need the extra index
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

# create convolutional base
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

# Add dense layers on top 
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

# Compile and train the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Evaluate the model
history = model.fit(train_images, train_labels, epochs=10, 
                    validation_data=(test_images, test_labels))
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

# print the accuracy at the end
print(test_acc)

\end{lstlisting}
\href{https://www.tensorflow.org/tutorials/images/cnn}{full tutorial}


\end{document}
